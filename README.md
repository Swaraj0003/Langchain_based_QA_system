# 🧠 RAG System using LangChain, FAISS, and Streamlit

This project implements a Retrieval-Augmented Generation (RAG) system using [LangChain](https://www.langchain.com/), [FAISS](https://github.com/facebookresearch/faiss), and [Streamlit](https://streamlit.io/). It allows you to ask questions over a local knowledge base (like a `data.txt` file) and get answers generated by an LLM, powered by retrieved context.

---

## 🚀 Features

- ⚡ Retrieval using FAISS vector store
- 🤖 Language generation via Hugging Face Transformers (`flan-t5-base`)
- 🧠 Embeddings using SentenceTransformers (`all-MiniLM-L6-v2`)
- 🖼️ Interactive Streamlit UI
- 📂 Local knowledge base support (`data.txt`)

---

## 🛠️ Setup

### 1. Clone the repository

```bash
git clone https://github.com/yourusername/rag-langchain-faiss.git

├── app.py                # Streamlit UI
├── rag_engine.py         # RAG pipeline logic
├── data.txt              # Local knowledge base
├── requirements.txt      # Python dependencies
├── README.md             # Project documentation


streamlit run app.py

