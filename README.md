# ğŸ§  RAG System using LangChain, FAISS, and Streamlit

This project implements a Retrieval-Augmented Generation (RAG) system using [LangChain](https://www.langchain.com/), [FAISS](https://github.com/facebookresearch/faiss), and [Streamlit](https://streamlit.io/). It allows you to ask questions over a local knowledge base (like a `data.txt` file) and get answers generated by an LLM, powered by retrieved context.

---

## ğŸš€ Features

- âš¡ Retrieval using FAISS vector store
- ğŸ¤– Language generation via Hugging Face Transformers (`flan-t5-base`)
- ğŸ§  Embeddings using SentenceTransformers (`all-MiniLM-L6-v2`)
- ğŸ–¼ï¸ Interactive Streamlit UI
- ğŸ“‚ Local knowledge base support (`data.txt`)

---

## ğŸ› ï¸ Setup

### 1. Clone the repository

```bash
git clone https://github.com/yourusername/rag-langchain-faiss.git

â”œâ”€â”€ app.py                # Streamlit UI
â”œâ”€â”€ rag_engine.py         # RAG pipeline logic
â”œâ”€â”€ data.txt              # Local knowledge base
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ README.md             # Project documentation


streamlit run app.py

